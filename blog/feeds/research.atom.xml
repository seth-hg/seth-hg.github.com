<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Life Sucks</title><link href="/blog/" rel="alternate"></link><link href="/blog/feeds/research.atom.xml" rel="self"></link><id>/blog/</id><updated>2012-10-05T00:00:00+08:00</updated><entry><title>关于CPU Cache零碎</title><link href="/blog/cpu-cache.html" rel="alternate"></link><updated>2012-10-05T00:00:00+08:00</updated><author><name>Seth Huang</name></author><id>tag:/blog,2012-10-05:cpu-cache.html</id><summary type="html">&lt;p&gt;读SCM方面的paper，经常要涉及到CPU Cache的一些东西，以前只关注外存了，对这些方面了解很少，这里把一些知识记录下来备忘。&lt;/p&gt;
&lt;div class="section" id="cache-mode"&gt;
&lt;h2&gt;Cache Mode&lt;/h2&gt;
&lt;p&gt;CPU Cache通常支持三种模式，Write-through、Write-back和Write-combining。前两种就比较常见，不需要解释了。Write-combining就比较特殊，按照我的理解它是一种针对大量写操作而优化的模式。对于写，它跟WB类似，把数据缓存起来，然后用burst方式一起写到memory，提高带宽的利用率。但是这种模式不保证指令按正确顺序执行，特别是对于读写混合的操作，比如写/读/写这样的指令序列，实际执行起来可能变成了读/写/写，如果前后指令之间存在数据依赖，执行结果就会出错。所以Write-combining不能用于普通的内存。目前这种模式的唯一应用是显存，因为有大量数据要写，而且对顺序性要求不高。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mtrr-pat"&gt;
&lt;h2&gt;MTRR &amp;amp; PAT&lt;/h2&gt;
&lt;p&gt;现代处理器通常都支持对不同的内存地址范围指定不同的cache模式，实现的方法就是MTRR和PAT。MTRR全称是Memory Type Range Registers，是CPU提供的一组特殊寄存器，用来指定某些内存地址范围的缓存模式。在Linux下可以通过/proc/mtrr文件查看当前的状体。比如我的是这样的：&lt;/p&gt;
&lt;pre class="literal-block"&gt;
reg00: base=0x000000000 (    0MB), size= 2048MB, count=1: write-back
reg01: base=0x07ff00000 ( 2047MB), size=    1MB, count=1: uncachable
reg02: base=0x0d0000000 ( 3328MB), size=  256MB, count=1: write-combining
&lt;/pre&gt;
&lt;p&gt;前面2GB是主存，之后的1MB大概是映射给了BIOS ROM，最后256MB是显存。&lt;/p&gt;
&lt;p&gt;PAT全称是Page Attribute Table，可以认为是MTRR的升级版，二者的关系类似于分段(segmentation)和分页(paging)的关系，MTRR只能粗粒度的指定某个地址范围，而且数量有限，但是PAT可以跟页表一样精确到页，为每个页面分别设置缓存模式。Intel从Pentium III开始支持PAT，很多其他CPU也支持。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="physically-or-virtually-indexed"&gt;
&lt;h2&gt;Physically or Virtually Indexed&lt;/h2&gt;
&lt;p&gt;CPU Cache是用地址来索引的，当访问某个内存地址时，只要在索引里查找是否有这个地址，就知道请求的数据在不在cache里。但是现代处理器都是有分页机制的，内存地址有物理地址和虚拟地址两种，用哪种地址来做cache索引就成了一个问题。Either way has its pros and cons. Physically indexed cache is simple, but it's also slow for lookups. Because it depends on MMU to translate virtual address to physical address. Things will get worse when TLB miss. Virtually indexed cache is much faster. However, it must deal with alias problem, i.e. a single physical address is mapped to multiple virtual addresses.&lt;/p&gt;
&lt;p&gt;x86是用物理地址做索引的 &lt;a class="footnote-reference" href="#id2" id="id1"&gt;[1]&lt;/a&gt; 。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="clflush-mfence"&gt;
&lt;h2&gt;clflush &amp;amp; mfence&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;clflush&lt;/em&gt; instruction invalidate a cache line through all cache levels. If the cache line contains uncommited data, it will be written to memory first.&lt;/p&gt;
&lt;p&gt;Similar to barrier I/O(BIO_BARRIER) at block level, the &lt;em&gt;mfence&lt;/em&gt; instruction is a mechanism to implement write ordering. It enforces that data updated before the instruction is commited before subsequent ones.&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="id2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://www.motherboardpoint.com/l1-l2-caches-and-mmu-t152345.html"&gt;http://www.motherboardpoint.com/l1-l2-caches-and-mmu-t152345.html&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary><category term="cache"></category><category term="scm"></category></entry><entry><title>Google怎样做研究</title><link href="/blog/google-hybrid-research.html" rel="alternate"></link><updated>2012-07-25T00:00:00+08:00</updated><author><name>Seth Huang</name></author><id>tag:/blog,2012-07-25:google-hybrid-research.html</id><summary type="html">&lt;p&gt;Google的三位大牛Alfred Spector、Peter Norvig、Slav Petrov在7月份的ACM Communication上发表了 &lt;a class="reference external" href="http://cacm.acm.org/magazines/2012/7/151226-googles-hybrid-approach-to-research/fulltext"&gt;一篇短文&lt;/a&gt; ，探讨在Google公司里如何开展研究工作。Google称自己的研究方法为“混合式研究”（Hybrid Research），即新技术研究和产品开发不做区分，鼓励项目团队在研究和工程之间寻找最合适的平衡点。总结了一下，有几个要点：&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Google进行的研究目的在于快速改进其产品，为用户提供更高质量的服务。因此Google的研究主要集中在与其产品密切相关的领域，其中大部分都不是特别新的研究领域，但是仍然有改进空间，特别是考虑到Google的数据量和用户规模。过于关注产品本身可能会错失一些发展机会，因此Google也设置了访问学者、实习生、员工科研奖励等一系列的政策，鼓励开拓新的研究领域。&lt;/li&gt;
&lt;li&gt;基于服务的分发模式保证即使一个小团队也能够迅速创建强大的系统，并为用户提供服务。这个一方面得益于强大的基础架构，系统的设计、开发、测试和维护过程都得到了简化。另一方面也得益于庞大的用户群体，Google可以很容易获得数据，方便进行实证研究（empirical research），在系统复杂度越来越高、规模越来越大、分析技术难以描述的情况下，实证研究的方法越来越重要。&lt;/li&gt;
&lt;li&gt;迭代式研究，研究过程从一开始就要求编写产品代码或者接近产品级的代码，不会专门设计一个用于研究的原型系统。通常由一个团队自始至终负责整个迭代过程，从研究思路的探索，到软件的开发和维护，甚至还要帮助服务的运维。这种模式减少了从研究到工程的技术转换风险，也保证了其产品真正能够从研究成果中受益。&lt;/li&gt;
&lt;li&gt;把长期研究任务分割成短期、可度量的部分。这种方法有利于激励团队，同时也能够更早的带来商业效益。如果某个项目过于复杂难以细分，也能够坚持长期的投入力量进行研究，比如Google Translate、Chrome和Google Health。如果长期项目的方向出现问题，敢于调整工作重心，即使项目已经向公众发布。&lt;/li&gt;
&lt;li&gt;鼓励学术交流。Google认为，通过跟学术界的交流，可以获得有益的反馈信息，培养未来的员工，创造合作机会，发现新的研究方向等等。因此Google愿意公开很多研究成果，包括GFS、MapReduce这样的基础性研究的成果。Google衡量一项研究是否成功，标准之一是看其是否对学术接产生了重大的影响。这里的影响一方面是通过发表论文（Google在2003年发表了13篇论文，2006年130篇，2011年279篇，其中很多已经成为准教科书），也包括发布开源项目（最具代表性的莫过于Android和Chromium）以及参与标准的制定(比如spdy协议和webm等)。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;文中列举了Google的五种常见研究模式：&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;以产品开发为主的团队在项目中提出了具有突破性的方案，变成了研究成果。Google的业务需要处理世界上最大的数据集，同时也要为大量用户提供服务，规模可谓空前，因此在产品开发的过程中遇到的问题很可能本身就是一个极有挑战性的研究课题。MapReduce、GFS、BigTable就是典型代表。&lt;/li&gt;
&lt;li&gt;研究团队的项目转化成新的产品或服务。Google翻译和语音搜索就是这样的项目。如果持续的研究能够进一步改进和扩展该产品，那么这种模式最合适不过了。&lt;/li&gt;
&lt;li&gt;研究团队的成果应用到现有的产品里。这是传统的研究模式，Google有大量真实的数据可以为研究提供支持，比如YouTube的声音和视频指纹算法，是在研究人员用大量真实数据进行测试之后，才投入生产应用的。&lt;/li&gt;
&lt;li&gt;工程团队和研究团队的合作项目，成果由工程团队转化到产品中。很多产品都需要新算法来提供高性能，在工程和研究两方面都有很大的挑战性。比如我们的市场算法研究小组和广告系统组，他们一起设计、优化和分析用于广告选择和优化的核心算法和市场机制。&lt;/li&gt;
&lt;li&gt;工程团队中的研究项目移交给研究团队。通常是一些具备通用性的研究项目，对多个产品都有重要意义，这种移交机制可以为这样的项目分配更多的时间和资源。比如YouTube的推荐算法，在多个工程团队里都遇到了同样的问题，于是就被转交给专门的研究小组，进行更加深入的研究。&lt;/li&gt;
&lt;/ol&gt;
</summary><category term="google"></category></entry><entry><title>文件系统一致性机制</title><link href="/blog/fs-consistency.html" rel="alternate"></link><updated>2012-06-03T00:00:00+08:00</updated><author><name>Seth Huang</name></author><id>tag:/blog,2012-06-03:fs-consistency.html</id><summary type="html">&lt;p&gt;文件系统存储在设备上的数据主要包括两部分，一部分是用户数据，另一部分是管理用户数据所需的元数据，主要包括三种信息：一是资源（主要是存储空间）的分配情况；二是文件系统的名字空间，也就是目录结构；三是文件索引，记录了文件内偏移地址和磁盘块地址的映射关系。由于一个文件系统操作通常涉及多个数据结构，需要修改多个磁盘扇区。以创建文件为例，既要分配和初始化索引节点，又要在父目录中插入新的目录项，还有可能要预分配一些磁盘块，这一个操作需要修改索引节点表、索引节点位图、父目录、磁盘块位图等等。但是磁盘并不支持跨越多个扇区的原子更新，要保证这个操作的原子性（操作或者成功，或者完全没有发生），就必须在文件系统中提供额外的机制，否则就有可能造成数据不一致。&lt;/p&gt;
&lt;p&gt;文件系统一致性可以分成三个层次。第一个层次是元数据一致，即元数据中的各种数据结构之间没有冲突，不存在已被分配但没有被引用的孤立inode或者block，也不存在错误或者重复的引用。仍然以创建文件为例，如果索引节点分配并初始化成功，但是父目录还没有修改，这个索引节点就成了孤立的，既不能被访问，也不能被回收。第二个层次是数据一致，不但要求元数据一致，还要求元数据中引用的数据块必须是属于该文件的，而不是垃圾数据，或者其他文件的数据。&lt;/p&gt;
&lt;p&gt;对于多数应用，达到第二层次就已经足够了。但是在某些特殊应用下，对文件的版本有比较严格的要求，比如用make编译软件，要根据源码文件的版本确定是否需要重新编译该文件。因此就有了第三个层次——版本一致，要求元数据中引用的数据块不但属于该文件，还要跟元数据中所标明的版本保持一致。虽然多数文件系统并不支持多版本，没有显式的版本号，但是inode中还有一个最后修改时间可以表示文件当前版本。&lt;/p&gt;
&lt;p&gt;常用的文件系统一致性机制有下面几种。&lt;/p&gt;
&lt;div class="section" id="fsck"&gt;
&lt;h2&gt;fsck&lt;/h2&gt;
&lt;p&gt;扫描文件系统的所有元数据，逐个检查各个数据结构之间是否匹配，修正可能存在的不一致。这种方法最简单，而且只有发生故障之后才需要进行，对文件系统的性能没有影响。不过缺点也很明显，一是必须离线进行，检查过程中不能提供服务；二是耗时长，由于要扫描整个卷，数据量越大，耗时越久；最后，这种方法只能保证元数据一致。常用的文件系统都提供了fsck工具。Valerie Henson设计了chunkfs &lt;a class="footnote-reference" href="#id9" id="id2"&gt;[1]&lt;/a&gt; ，用分治的策略改进一致性检查过程。把一个卷划分成若干相对独立的chunk，一个文件操作只需要更新一个chunk之内的磁盘块。这样即使更新操作意外中断，也只有少数几个chunk是不一致的，只需要扫描这些chunk即可，大大缩短了检查的时间。&lt;/p&gt;
&lt;p&gt;Fsck是基于预先制定的规则的，而这些规则往往是来自于经验，比如指向文件数据块的指针不能超过设备地址范围，标记为已分配的资源必须被引用等等。根据这些规则进行的一致性检查，缺乏全局观，只能发现局部问题，而对某些问题则无能为力。比如，文件A的inode中的块指针出错，原本该指向一个间接块的，现在指向了一个错误的数据块，在进行fsck时，只能发现这个数据块中的内容违背了规则，但无法查出错误的原因是inode的错误。为了解决这个问题，Wang et al. &lt;a class="footnote-reference" href="#id10" id="id3"&gt;[2]&lt;/a&gt; 提出了利用快照，通过比较structural edit distance，找到跟文件系统当前状态最为接近的快照，辅助进行修复。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="journaling"&gt;
&lt;h2&gt;Journaling&lt;/h2&gt;
&lt;p&gt;Journal又称作Write-ahead log，即在实际更新数据之前先把更新操作记录在日志里，这种方法严格要求日志的更新在实际更新操作之前完成。这种方法能达到的一致性层次取决与日志里记录的内容，如果日志中只记录元数据操作，则只能保证元数据一致，如果记录日志中包含数据，就可以保证版本一致。由于每次更新操作都要增加额外的写日志开销，对文件系统写性能的影响比较大。Ext3/4文件系统采用了这种方法。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="copy-on-write"&gt;
&lt;h2&gt;Copy-on-write&lt;/h2&gt;
&lt;p&gt;每次更新操作都复制原有数据并把更新写到新的位置，而不会覆盖旧数据，因而能够保证版本一致，也没有额外的写日志开销。支持CoW的文件系统通常又称作write anywhere file system &lt;a class="footnote-reference" href="#id11" id="id4"&gt;[3]&lt;/a&gt; 。由于文件系统中的数据是采用树状结构进行索引的，对其中一个数据块的CoW，会导致更新操作逐层向上扩散直到树根。例如，在文件写操作的时候修改了一个数据块，进行CoW的同时，需要修改文件索引节点中的指针以指向新的磁盘块，又会触发对索引节点的CoW，接着又要触发对父目录的CoW……一直到根目录，因此目录层次越深，更新的开销也就越大。为了解决这个问题，支持CoW的文件系统通常采用B+树作为磁盘索引结构 &lt;a class="footnote-reference" href="#id12" id="id5"&gt;[4]&lt;/a&gt; ，所有的数据都存放在叶子节点中，当修改一个叶子节点时，需要拷贝从根结点到该节点之间的整条路径，这样更新操作的开销只取决于树的深度，也就是文件系统中实际存储数据的多少。CoW的实现通常比较复杂，需要大量的代码，支持这种方式的文件系统有Solaris的ZFS和Linux的btrfs。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="soft-updates"&gt;
&lt;h2&gt;Soft updates&lt;/h2&gt;
&lt;p&gt;这是BSD大牛Marshall Kirk McKusick &lt;a class="footnote-reference" href="#id13" id="id6"&gt;[5]&lt;/a&gt; 提出的方法，通过跟踪缓存在内存里的文件系统数据结构之间的依赖关系，控制磁盘更新的顺序，以保证磁盘上的数据总是处于一致的状态。相比前面两种方法，即没有写日志的开销，也不会造成链式的更新，只有在某些情况下可能需要对更新操作进行回滚，然后重新执行，因此这种方法的性能开销是最低的。由于正确的控制磁盘更新的顺序非常复杂，目前只有BSD的UFS里实现了这种算法。&lt;/p&gt;
&lt;p&gt;从以上这些常用的方法中不难看出，磁盘块的更新顺序是保证文件系统一致性的一个重要的问题，因为文件系统本质上是依靠指针关系建立起来的索引结构，所以要保证一致性，必须要被引用的数据块在指针更新之前到达磁盘。基于这个观点，Frost et al. &lt;a class="footnote-reference" href="#id14" id="id7"&gt;[6]&lt;/a&gt; 提出了一种通用的write-before语义，并实现了基于patch的更新方法，在保证一致性的基础上，简化了文件系统的开发。另一方面，Chidambaram et al. &lt;a class="footnote-reference" href="#id15" id="id8"&gt;[7]&lt;/a&gt; 通过实验发现，严格要求磁盘块按照一定的顺序进行更新会限制磁盘带宽的利用率，降低文件系统的性能，因此提出了用反向指针（back pointer）保证一致性的方法，这种方法为每一个inode、dentry和数据块增加一个指向其引用者的反向指针，在更新的时候，只需要一个I/O操作就可以同时更新被引用对象和其反向指针，通过对比指针和反向指针，可以实时发现文件系统的异常，并修正某些错误，避免了耗时的离线fsck，同时也提升了写性能。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="reference"&gt;
&lt;h2&gt;Reference&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="id9" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://static.usenix.org/events/hotdep06/tech/prelim_papers/henson/henson.pdf"&gt;Chunkfs: using divide-and-conquer to improve file system reliability and repair&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id10" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://research.microsoft.com/apps/pubs/?id=80943"&gt;Crystal: The Power of Structure Against Corruptions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id11" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://ng.gnunet.org/sites/default/files/10.1.1.40.3691.pdf"&gt;File system design for an NFS file server appliance&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id12" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id5"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://static.usenix.org/event/lsf07/tech/rodeh.pdf"&gt;B-trees, shadowing, and clones&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id13" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id6"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://static.usenix.org/event/usenix99/full_papers/mckusick/mckusick.pdf"&gt;Soft updates: A technique for eliminating most synchronous writes in the fast filesystem&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id14" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id7"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://www.sosp2007.org/papers/sosp169-frost.pdf"&gt;Generalized File System Dependencies&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id15" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id8"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://static.usenix.org/events/fast12/tech/full_papers/Chidambaram.pdf"&gt;Consistency Without Ordering&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary><category term="file system"></category><category term="reliability"></category></entry><entry><title>Dynamic Information Flow Tracking</title><link href="/blog/dynamic-info-flow-tracking.html" rel="alternate"></link><updated>2012-05-18T00:00:00+08:00</updated><author><name>Seth Huang</name></author><id>tag:/blog,2012-05-18:dynamic-info-flow-tracking.html</id><summary type="html">&lt;p&gt;Dynamic Information Flow Tracking &lt;a class="footnote-reference" href="#id8" id="id1"&gt;[1]&lt;/a&gt; ，就是通过分析进程执行过程中各个数据对象之间的因果关系（causality），跟踪某些敏感或可疑数据在程序执行过程中的传播，将受到影响的所有数据标记出来，并根据预定的策略执行相应的操作。近几年，有很多研究表明DIFT可以成功的应用在安全领域，有效的提高软件系统抵御入侵的能力。&lt;/p&gt;
&lt;p&gt;用论文 &lt;a class="footnote-reference" href="#id9" id="id2"&gt;[2]&lt;/a&gt; 中一个例子来说明一下。图中给出的代码存在漏洞，在第5行进行字符串拷贝的时候没有检查参数arg2的长度，攻击者可以用缓冲区溢出的方法，给出一个很长的arg2，从而覆盖掉localIP，获得执行非法操作的权限。&lt;/p&gt;
&lt;img alt="buffer overflow example" src="/images/buffer-overflow-exp.png" style="height: 350px;" /&gt;
&lt;p&gt;有了DIFT，只需要将用户输入的参数当作可疑数据源，这样当字符串拷贝越界时，localIP就会被打上标记，在后面使用localIP的时候，只需要检查localIP的标记，就可以检测到攻击行为。除此之外，如果将网络作为可疑数据源，跟踪从网络获取的数据在进程执行过程中的传播，阻止这些数据被当作指令执行，可以有效的预防很多诸如cross-site scripting和SQL injection之类的入侵。&lt;/p&gt;
&lt;p&gt;DIFT不但可以用于入侵检测，还可以用于被入侵之后的数据恢复 &lt;a class="footnote-reference" href="#id10" id="id3"&gt;[3]&lt;/a&gt; 。入侵者通常会修改文件系统中的数据，比如删除系统日志隐藏入侵行为或者留个后门什么的。当发现系统被入侵之后，需要及时的将系统恢复到入侵之前的状态。简单的将整个系统回滚到入侵点之前的状态，不但效率低，而且会损失一部分合法的数据。如果能够的识别哪些进程、哪些操作受到了入侵行为的影响，就可以有选择的进行恢复。&lt;/p&gt;
&lt;p&gt;除了抵御入侵，DIFT还可以用来保护用户隐私，防止恶意程序泄露用户数据。比如TaintEraser &lt;a class="footnote-reference" href="#id11" id="id4"&gt;[4]&lt;/a&gt; 就是通过跟踪数据流，阻止敏感数据向外传输。TaintDroid &lt;a class="footnote-reference" href="#id12" id="id5"&gt;[5]&lt;/a&gt; 则在Android手机上实现了类似的功能。&lt;/p&gt;
&lt;p&gt;当然，这种技术的用途并不局限于安全领域。比如 &lt;a class="footnote-reference" href="#id13" id="id6"&gt;[6]&lt;/a&gt; 就把它用在了配置故障诊断上。很多的开源软件都有数量繁多的配置参数，出现配置错误时，诊断和查找错误原因是一个很头疼的工作。通过跟踪配置文件中每个token在进程执行过程中的数据流，以及它们对控制流的影响，可以确定每一个数据对象所依赖的token。如果一个数据对象导致程序执行出错，那么它所依赖的这些token就很可能是造成错误的原因。&lt;/p&gt;
&lt;p&gt;近几年比较热门的Provenance &lt;a class="footnote-reference" href="#id14" id="id7"&gt;[7]&lt;/a&gt; ，我认为也应该算作是DIFT的一种形式，不过针对的是持久存储的数据对象，比如文件或数据库记录。相对与进程内部的数据流，provenance的粒度要粗一些。&lt;/p&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="id8" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1042&amp;amp;context=ece"&gt;Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id9" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1381306.1382156"&gt;From Speculation to Security: Practical and Efficient Information Flow Tracking Using Speculative Hardware&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id10" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1924943.1924950"&gt;Intrusion recovery using selective re-execution&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id11" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[4]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1945023.1945039"&gt;TaintEraser: protecting sensitive data leaks using application-level taint tracking&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id12" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id5"&gt;[5]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1924943.1924971"&gt;TaintDroid: an information-flow tracking system for realtime privacy monitoring on smartphones&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id13" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id6"&gt;[6]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1924943.1924960"&gt;Automating configuration troubleshooting with dynamic information flow analysis&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id14" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id7"&gt;[7]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://www.eecs.harvard.edu/syrah/pass/pubs/usenix06.pdf"&gt;Provenance-Aware Storage Systems&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary><category term="security"></category></entry><entry><title>Speculative &amp; Lazy Execution</title><link href="/blog/speculative-lazy-execution.html" rel="alternate"></link><updated>2012-04-13T00:00:00+08:00</updated><author><name>Seth Huang</name></author><id>tag:/blog,2012-04-13:speculative-lazy-execution.html</id><summary type="html">&lt;div class="section" id="speculative-execution"&gt;
&lt;h2&gt;Speculative Execution&lt;/h2&gt;
&lt;p&gt;Speculative Execution，直译过来就是“投机执行”（通常的说法貌似是“预测执行”，不过我觉得直译的更有味道一些），是一种性能优化方法。提高性能的重要方法之一是并行，比如流水线，利用不同部件之间的并行来屏蔽延迟，提高整体性能。但是如果前后两个任务之间存在依赖关系，比如下面这种情况，condition()和do_something()/do_something_else()之间不能并行，流水线就失效了。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;condition&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;do_something&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="n"&gt;do_something_else&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;投机执行就是解决这个问题的。虽然后续的操作依赖于condition()的结果，但是在特定的情况下，condition()的结果是可以预测的，比如99%是true，那么就可以让condition()和do_something()并发执行。很明显，这种方法依赖于预测的准确率，准确率越高，性能提升也就越大。这种投机的思想在计算机系统里应用很广。&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;strong&gt;分支预测（branch prediction）&lt;/strong&gt; 。现代处理器里面常用的一种技术，当执行到形如“if-then-else”的分支指令时，通过预测的方法提高指令的并行度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Splitstream&lt;/strong&gt; 。这也是处理器中的一种技术，不过相比前者还不够成熟，应用也较少。采用这种技术的处理器在执行程序的时候会启动两个流程分别执行，一个叫做A-stream，会过滤掉程序中一些不重要的指令，只执行少部分指令。另一个是R-stream，执行原始程序。因为A-stream中少了很多指令，所以执行更快。在A-stream执行的时候，已经把指令和数据载入到处理器的cache里，当R-stream执行的时候，就无需访问内存，因此这种方法可以屏蔽内存访问的部分延迟，提高执行效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文件预取（prefetch）&lt;/strong&gt; 。文件系统通常假定用户对文件的访问是顺序的，因此用户读取某一块的时候，也会顺便把后面若干块一起读到缓存，这样当用户请求后面的块时，就可以直接从缓存获取数据，大大降低了延迟。顺序预取是最常见的预取方式，但是只适用于顺序访问占主导的情况，如果是随机访问为主，这种预取反而会降低性能。CMU的Fay Chang提出了一种 &lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=296806.296807&amp;amp;coll=DL&amp;amp;dl=ACM&amp;amp;CFID=97289604&amp;amp;CFTOKEN=10555591"&gt;预取算法&lt;/a&gt; ，采用的是另外一种投机执行的方式。我们知道大多数程序采用的是阻塞式I/O，程序会阻塞直到I/O完成。Chang的方法在进程阻塞时，会fork出一个新进程代替原进程继续执行，不过这个新进程不会执行实际的I/O操作，而是会产生一些hints给文件系统。文件系统根据hints进行预取。这种方法不局限于顺序访问，适用性更广，不过具体效果就要看投机的成功率了。&lt;/li&gt;
&lt;/ol&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;&lt;strong&gt;Optimistic Concurrency Control&lt;/strong&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;避让算法&lt;/strong&gt; 。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;前面几种只是比较常见的应用，其实投机执行的应用远不止这些。比如密歇根大学的Edmund B. Nightingale就把这种方法用在了 &lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=1095810.1095829&amp;amp;coll=DL&amp;amp;dl=ACM&amp;amp;CFID=97289604&amp;amp;CFTOKEN=10555591"&gt;分布式文件系统&lt;/a&gt; 里。分布式文件系统里存在很多具有依赖关系的操作，比如NFS里，文件写操作分成了write和commit两步，write把数据写到服务器，而commit确保数据永久存储到设备上。显然commit必须在write成功之后才能进行。在网络正常，尤其是在局域网内的情况下，write操作是很少会失败的，因此可以假定write操作成功，在其返回之前就发出commit请求，这样就屏蔽了部分等待时间，减少了整个操作的延迟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;只要是存在因依赖造成等待的地方，就有投机的可能&lt;/strong&gt; 。不过要想提高性能，还要求投机的成功率比较高，换句话说就是对所依赖的结果预测比较准确，否则大量无效的执行反而会浪费资源，降低性能。另外在有些情况下，特别是涉及I/O操作的时候，错误的投机执行可能会造成一些副作用，比如修改文件，因此在这种情况下还要求能够正确的将系统恢复到之前的状态，以确保结果正确。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lazy-execution"&gt;
&lt;h2&gt;Lazy Execution&lt;/h2&gt;
&lt;p&gt;跟speculative execution相反，前者是在前途并不明朗的情况下投机冒进，而后者则是将本来可以完成的任务延后执行。Lazy execution的典型应用就是写缓存。将数据缓暂存在缓存空间，一方面可以屏蔽掉实际写操作的延迟，因为缓存的速度通常要快得多；另一方面也可以把对同一数据单元的多次更新，以及对多个连续单元的更新合并成一个写操作，达到更高的写性能。当然这样也会增加风险，如果缓存失效，那么缓存中还没有写下去的数据就丢失了。&lt;/p&gt;
&lt;p&gt;Lazy execution的另一个例子是日志（logging）。在更新数据的时候，并不直接更新现有的数据，而是将更新操作以日志的形式记录下来。这样做的好处就是可以避免由于更新操作意外中断（比如突然断电）造成数据不一致，ext3文件系统里的journaling和日志文件系统（log-structured file system）就是这个原理。&lt;/p&gt;
&lt;p&gt;总结一下，不管是speculative execution还是lazy execution，都是通过改变某些操作的执行时机来获益。&lt;/p&gt;
&lt;/div&gt;
</summary><category term="performance"></category></entry></feed>